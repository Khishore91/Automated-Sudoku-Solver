{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Mnist Digits Dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './Sudoku_Numbers'\n",
    "digit_list = os.listdir(data_dir)\n",
    "x_train = x_train.tolist()\n",
    "y_train = y_train.tolist()\n",
    "\n",
    "\n",
    "for digit in digit_list:\n",
    "    digit_path = os.path.join(data_dir,digit)\n",
    "    for img_name in os.listdir(digit_path):\n",
    "        img = cv2.imread(os.path.join(digit_path,img_name), 0)\n",
    "        x_train.append(img)\n",
    "        y_train.append(int(digit))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No of Total Traning images:  60708\n"
     ]
    }
   ],
   "source": [
    "print(\"No of Total Traning images: \",len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train, dtype='float32')\n",
    "y_train = np.array(y_train, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zero_digit(img_arr,labels):\n",
    "    index_val = np.where(labels == 0)\n",
    "    #index_val = index_val.to_list()\n",
    "    \n",
    "    img_arr = np.delete(img_arr,index_val, axis=0)\n",
    "    label_arr = np.delete(labels, index_val)\n",
    "    \n",
    "    return img_arr, label_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = remove_zero_digit(x_train, y_train)\n",
    "x_test, y_test = remove_zero_digit(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_,x_train = cv2.threshold(x_train,127,255,cv2.THRESH_BINARY)\n",
    "_,x_test = cv2.threshold(x_test,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False,    # randomly flip images\n",
    "        #shear_range = 2,\n",
    "        #brightness_range = [0.9, 1.1]\n",
    "        )     \n",
    "\n",
    "datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Parameters Initialization\n",
    "batch_size = 86\n",
    "epochs = 10\n",
    "input_shape= (28,28,1)\n",
    "train_val_model = False\n",
    "train_final_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 26, 26, 32)        320       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 12, 12, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 12, 12, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 6, 6, 64)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2304)              0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               590080    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 9)                 2313      \n=================================================================\nTotal params: 657,385\nTrainable params: 657,385\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(9, activation = \"softmax\"))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = datagen.flow(x_train, y_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './tf_check/checkpoint_val/checkpoint_val'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_val_model:\n",
    "    history = model.fit(train_data_gen, \n",
    "                        steps_per_epoch=len(x_train) / batch_size, \n",
    "                        epochs= epochs, \n",
    "                        validation_data= (x_test, y_test), \n",
    "                        validation_batch_size= batch_size,\n",
    "                        callbacks= model_checkpoint_callback)\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    model.save('digit_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the results of Training\n",
    "if train_val_model:\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.savefig('./train_eval.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining both train and test data for fitting the final model\n",
    "x_digit = np.vstack((x_train, x_test))\n",
    "y_digit = np.concatenate((y_train, y_test))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of X: (63805, 28, 28, 1) and Y: (63805,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X: {} and Y: {}\".format(x_digit.shape,y_digit.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_gen = datagen.flow(x_digit, y_digit, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './tf_check/checkpoint_all/checkpoint_all'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_final_model:\n",
    "    history_final = model.fit(final_data_gen, \n",
    "                            steps_per_epoch=len(x_digit) / batch_size, \n",
    "                            epochs= epochs,\n",
    "                            callbacks= model_checkpoint_callback)\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    model.save('Final_digit_classifier.h5')\n",
    "\n",
    "    #Visualizing the results of Training\n",
    "\n",
    "    acc = history_final.history['accuracy']\n",
    "    loss = history_final.history['loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflowjs as tfjs\n",
    "#tfjs.converters.save_keras_model(model, \"tfjs_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('./digit_classifier.h5')\n",
    "digit = cv2.imread('./Sudoku_Numbers/5/image360.png',0)\n",
    "print(np.argmax(model.predict(digit.reshape(-1,28,28,1))[0])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}